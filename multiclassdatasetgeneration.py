# -*- coding: utf-8 -*-
"""MultiClassDataSetGeneration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X_mfgSUst_rfIP6vzw6k96ssZG4_ha5v

# Generation of Data Sets
"""

import numpy as np

#Each features distribution and creation
f1 = np.random.normal(1, 0.2, 50000)
f2 = np.random.normal(20, 1, 50000)
f3 = np.random.random(50000)
f4 = np.random.normal(50, 30, 50000)
f5 = np.random.normal(2, 0.15, 50000)
f6 = np.random.exponential(2, 50000)
f7 = np.random.normal(0.04, 0.006, 50000)
f8 = np.random.normal(4, 0.03, 50000)
f9 = np.random.normal(15, 7, 50000)
f10 = np.random.normal(56, 12.5, 50000)
f11 = np.random.beta(5, 4, 50000)
#f12 = np.random.beta(10, 2, 50000)
#f13 = np.random.normal(-4, 0.05, 50000)
#f14 = np.random.random(50000)
#f15 = np.random.normal(45, 23, 50000)
#f16 = np.random.normal(89, 14, 50000)
#f17 = np.random.random(50000)
#f18 = np.random.normal(150, 34, 50000)
#f19 = np.random.normal(2, 0.5, 50000)
#f20 = np.random.exponential(10, 50000)

#appending numpy arrays to overall features array
all = []
#loop through global variables appending arrays of features
for i in range(11):
  all.append(globals()[f"f{i+1}"])
#Transposing so each column is now a feature 
all = np.array(all)
features = all.transpose()

"""### FDIA Function
- Takes generated features
- Injects half of the rows
- Chooses random amount of readings to inject
- at random indices
- generates a random gaussian distribution according to params to negate from values
- generates labels as it iterates, 0 for untouched, 1 for compromised
"""

#False Data Injection Function
def inject(features, mean, std):
  #labels initialization
  labels = []
  #iterating through all features
  for row in features:
    #random chance to inject or leave
    if np.random.random() < 0.3333:
      #how many sensors to attack
      sensors_to_attack = np.random.randint(5, 9)
      #what indices to attack
      indices = np.random.choice(range(11), sensors_to_attack, replace=False)
      #what values to inject into indices
      values_to_inject = np.random.normal(mean, std, sensors_to_attack)
      #negating values from indices in row
      row[indices] -= values_to_inject
      #append 1 for compromised reading
      labels.append(1)
    else:
      labels.append(0)
  #return tuple of updated features and generated labels
  return (features, labels)

#tuple of new injected features and labels
inj_tuple = inject(features, 2, 0.5)
features = inj_tuple[0]
labels = inj_tuple[1]

"""###Dos Function
- iterates through all rows
- if random values less than a third
- inject randomly generated reading 
- append label of 2 for DoS
"""

#Convertion of features back to list for speedup
features = [list(i) for i in features]

def Dos(features, labels, scale=1):
  #iterate through features
  for i in range(len(features)):
    if np.random.random() < 0.3333:
      #send in that dos
      to_send = list(np.random.random(11)*scale)
      #insertion
      features.insert(i, to_send)
      #label insertion
      labels.insert(i, 2)
  return (features, labels)

#Simulating DoS and getting final FDIA and DoS data and labels
final_data = Dos(features, labels, scale=50)
features, labels = final_data[0], np.array(final_data[1])

#np arrays for ML
features = np.array(features)
labels = np.array(labels)

#lennies
print(f"length of features: {len(features)}\nlength of labels: {len(labels)}")

"""###Train test data"""

#split for train and test data
from sklearn.model_selection import train_test_split

#Splitting data into train and test data
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=5, shuffle=True)

"""###Feature Scaling
- normalizing data
- subtracts mean and divides by unit variance
"""

#importing scaler
from sklearn.preprocessing import StandardScaler

#getting scaler
scaler = StandardScaler()
#transforming train and test features
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""###Machine Learning"""

#Random Forest for initial test
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

#initializing model
rf = RandomForestClassifier(n_estimators=200, max_depth=4, criterion='entropy', random_state=5)
#fitting training data
rf.fit(X_train, y_train)

#getting accuracy
y_pred = rf.predict(X_test)
#accuracy score of predictions
print(f"Accuracy of Random Forest: {round(accuracy_score(y_test, y_pred), 2)*100}%")

"""### Testing Model on Load Min Supply Data Set"""

#pandas for load min supply data
import pandas as pd

#getting data from files
features = np.array(pd.read_csv(r'features.csv', sep=',', header=0))
labels = np.array(pd.read_csv(r'labels.csv', sep=',', header=0))

#making lists for DoS injection
labels = [list(i) for i in labels]
features = [list(i) for i in features]

#change int 2 to list [2]
labels = [i if i != 2 else [2] for i in labels]

#injecting DoS
features, labels = Dos(features, labels, scale=50)

print(labels)

#np arrays for ML
features = np.array(features)
labels = np.array(labels)

#getting accuracy
y_pred = rf.predict(features)
#accuracy score of predictions
print(f"Accuracy of Random Forest on LoadMinSupply: {round(accuracy_score(labels, y_pred), 2)*100}%")

#testing turning 2 int into [2]
nums = [[0], [1], [1], [0], [0], 2, [1], [1], [0], 2, [0], [1], 2]

nums = [i if i != 2 else [2] for i in nums]

nums

#NEED TO FIX 2 LABEL PROBLEM
#- type of label 2 insertion is different to original label
#- FULLY UNDERSTAND STRUCTURE AND DATA TYPES OF FEATURES AND LABELS BEFORE WORKING RF MODEL AND GET THIS ONE TO PRODUCE EXACT SAME STRUCTURE

