# -*- coding: utf-8 -*-
"""RepAtt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fRPzJtPjHHWAt2NYrRyod96p_iumHCdz

#Replay Attack plotting and ML
"""

#libraries
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

#function for replay attack of data
def replay(data):
  #unpack data tuple
  features = [list(i) for i in data[0]]
  labels = list(data[1])
  new_features = []
  new_labels = []
  #iterate and repeat
  for i in features:
    if np.random.random() < 0.2:
      #how many repeats at random
      repeats = np.random.randint(10, 20)
      for j in range(repeats):
        new_features.append(i)
        new_labels.append(1)
    else:
      new_features.append(i)
      new_labels.append(0)
  return (np.array(new_features), np.array(new_labels))

#csv
df = pd.read_csv(r'LoadMinPower.csv')
#replaying data
df.drop(df.columns[[0,1]], axis=1, inplace=True)
replayed = replay((df.to_numpy(), [0 for i in range(len(df))]))
features, labels = replayed[0], replayed[1]

"""####Plotting Data after Repeat"""

#y values as sensors 1, 5 and 11
y = np.array([i[0] for i in features][:200])
y2 = np.array([i[4] for i in features][:200])
y3 = np.array([i[10] for i in features][:200])
#Mean and Variance to show change
print(f" Sensor 1 Mean: {y.mean()}, Variance: {y.var()}")
print(f" Sensor 5 Mean: {y2.mean()}, Variance: {y2.var()}")
print(f" Sensor 11 Mean: {y3.mean()}, Variance: {y3.var()}")
#counter for values over time
x = np.arange(0, len(y))
#Plotting
plt.figure(figsize=(10,8))
plt.xlabel('Reading No.',fontsize=14)
plt.ylabel('Sensor Reading',fontsize=14)
plt.title('Sensor Readings After Replay Attack',fontsize=16)
plt.plot(x,y,label='Sensor 1')
plt.plot(y2, label = 'Sensor 5')
plt.plot(y3, label = 'Sensor 11')
plt.legend(loc='upper right')
plt.savefig('LoadMinSensorsafterReplayAttack')
plt.show()

"""####ML"""

#ML model imports sklearn library
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

#train test data
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=1, shuffle=True)

"""## Decision Tree Classifier"""

#import decision tree classifier
from sklearn.tree import DecisionTreeClassifier
#metric for accuracy score of classifications
from sklearn.metrics import accuracy_score

#decision tree initialized
tree = DecisionTreeClassifier()
#fitting training data
tree.fit(X_train, y_train)
#getting predictions
tree_preds = tree.predict(X_test)
#accuracy score of Decision Tree Classifier
print(f"Accuracy of Decision Tree: {round(accuracy_score(y_test, tree_preds)*100)}")

"""## KNN Nearest Neighbour Classifier"""

#Import KNN from sklearn
from sklearn.neighbors import KNeighborsClassifier

#KNN classifier
knn_model = KNeighborsClassifier()
#fitting training data
knn_model.fit(X_train, y_train)
#getting predictions of KNN
knn_predictions = knn_model.predict(X_test)
#Accuracy of KNN
print(f"Accuracy of KNN: {round(accuracy_score(y_test, knn_predictions)*100)}%")

"""## SVM Classifier """

# #SVM import
# from sklearn.svm import SVC

# #Support Vector Machine Implementation
# svm = SVC()
# #fitting training data
# svm.fit(X_train, y_train)
# #predictions of SVM
# svm_predictions = svm.predict(X_test)
# #accuracy score of SVM
# print(f"Accuracy of SVM: {round(accuracy_score(y_test, svm_predictions)*100)}%")

# #visualizing the support vectors
# support_vectors = svm.support_vectors_
# plt.scatter(X_train[:,0], X_train[:,1])
# plt.scatter(support_vectors[:,0], support_vectors[:,1], color='red')
# plt.figure(figsize=(8,6))
# #plt.title('Support Vectors')
# plt.show()

"""## Random Forest Classifier using SKLearn"""

#libraries
from sklearn.ensemble import RandomForestClassifier

#Model initialized
rf_model = RandomForestClassifier(200)
#fitting training data, 'ravel()' to get in flat matrix form
rf_model.fit(X_train, y_train)
#getting rf predictions of test data
rf_predictions = rf_model.predict(X_test)
#getting accuracy score of predictions
print(f"Accuracy of Random Forest: {round(accuracy_score(y_test, rf_predictions)*100)}%")

"""## XGBoost Classifier"""

#xgboost library
from xgboost import XGBClassifier

#XGBoost classifier
x_model = XGBClassifier()
#fitting training data
x_model.fit(X_train, y_train)
#getting predictions of XGBoost
x_predictions = x_model.predict(X_test)
#Accuracy of XGBoost
print(f"Accuracy of XGBoost: {round(accuracy_score(y_test, x_predictions)*100)}%")

"""## Convolutional Neural Network Model Creation using Keras"""

#keras for network implementation
from tensorflow.keras.models import Sequential, save_model, load_model
from tensorflow.keras.layers import Conv1D, Dropout, MaxPool1D, Flatten, Dense, BatchNormalization, LeakyReLU
from tensorflow.keras.callbacks import EarlyStopping

#reshape train data to fit into CNN
X_train_cnn = X_train.copy().reshape(len(X_train), 11, 1)

#callbacks to avoid overfitting
callback = EarlyStopping(monitor='accuracy', patience=4)

"""### CNN1"""

#Building the model
cnn1 = Sequential()
cnn1.add(Conv1D(filters=100, kernel_size=3, strides=1, activation='relu', input_shape=(11,1)))
cnn1.add(Conv1D(filters=200, kernel_size=3, strides=1, padding = 'same', activation='relu'))
cnn1.add(BatchNormalization())
cnn1.add(LeakyReLU())
cnn1.add(Dropout(0.5))
cnn1.add(Conv1D(filters=100, kernel_size=3, strides=1, activation='relu'))
cnn1.add(Dropout(0.5))
cnn1.add(Conv1D(filters=50, kernel_size=3, strides=1, padding = 'same', activation='relu'))
cnn1.add(Dropout(0.5))
cnn1.add(Conv1D(filters=100, kernel_size=3, strides=1, activation='relu'))
#cnn1.add(BatchNormalization())
#cnn1.add(LeakyReLU())
cnn1.add(Flatten())
cnn1.add(Dense(100, activation='relu'))
cnn1.add(Dense(1, activation='sigmoid'))
print(cnn1.summary())
cnn1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#Training the model
cnn1.fit(X_train_cnn, y_train, epochs=5, batch_size=500, validation_split=0.2, verbose=2)

"""### CNN2"""

#Building the model
cnn2 = Sequential()
cnn2.add(Conv1D(filters=100, kernel_size=3, strides=1, activation='relu', input_shape=(11,1)))
cnn2.add(Dropout(0.5))
cnn2.add(BatchNormalization())
cnn2.add(LeakyReLU())
cnn2.add(Conv1D(filters=50, kernel_size=3, strides=1, padding = 'same', activation='relu'))
cnn2.add(Dropout(0.5))
cnn2.add(Flatten())
cnn2.add(Dense(100, activation='relu'))
cnn2.add(Dense(1, activation='sigmoid'))
print(cnn2.summary())
cnn2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#Training the model
cnn2.fit(X_train_cnn, y_train, epochs=5, batch_size=500, validation_split=0.2, verbose=0)

"""### CNN3 """

#Building the model
cnn3 = Sequential()
cnn3.add(Conv1D(filters=16, kernel_size=2, strides=1, activation='relu', input_shape=(11,1)))
cnn3.add(Dropout(0.5))
cnn3.add(Conv1D(filters=32, kernel_size=2, strides=1, activation='relu', input_shape=(11,1)))
cnn3.add(Flatten())
cnn3.add(Dense(20, activation='relu'))
cnn3.add(Dense(1, activation='sigmoid'))
print(cnn3.summary())
cnn3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#Training the model
cnn3.fit(X_train_cnn, y_train, epochs=5, batch_size=500, validation_split=0.2, verbose=0)

"""## CNN Model Accuracy Scores"""

#Reshape test data for scores
X1_test = X_test.copy().reshape(len(X_test), 11, 1)

"""###### CNN1"""

#Predictions with CNN
cnn1_preds = cnn1.evaluate(X1_test, y_test, verbose=0)
#accuracy of CNN1
print(f"Accuracy of CNN1: {round(cnn1_preds[1]*100)}%")

"""###### CNN2"""

#Predictions with CNN
cnn2_preds = cnn2.evaluate(X1_test, y_test, verbose=0)
#accuracy of CNN2
print(f"Accuracy of CNN2: {round(cnn2_preds[1]*100)}%")

X1_test.shape

y_test.shape

"""###### CNN3"""

#Predictions with CNN
cnn3_preds = cnn3.evaluate(X1_test, y_test, verbose=0)
#accuracy of CNN2
print(f"Accuracy of CNN3: {round(cnn3_preds[1]*100)}%")

"""####Testing on Max Supply"""

#csv
df = pd.read_csv(r'LoadMaxPower.csv')
#replaying data
df.drop(df.columns[[0,1]], axis=1, inplace=True)
replayed = replay((df.to_numpy(), [0 for i in range(len(df))]))
max_features, max_labels = replayed[0], replayed[1]

"""####Getting the models predictions and plotting confusion matrices"""

#Decision Tree predictions
dt_pred = tree.predict(max_features)
print(f" Decision Tree: {accuracy_score(max_labels, dt_pred)}")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, dt_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#KNN
knn_pred = knn_model.predict(max_features)
print(f" KNN: {accuracy_score(max_labels, knn_pred)}")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, knn_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

# #SVM
# svm_pred = svm.predict(max_features)
# print(f" SVM: {accuracy_score(max_labels, svm_pred)}")
# #Confusion Matrix
# tn, fp, fn, tp = confusion_matrix(max_labels, svm_pred).ravel()
# print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#Random Forest
rf_pred = rf_model.predict(max_features)
print(f" Random Forest: {accuracy_score(max_labels, rf_pred)}")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, rf_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#XGBoost
xgb_pred = x_model.predict(max_features)
print(f" XGBoost: {accuracy_score(max_labels, xgb_pred)}")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, xgb_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#reshape features for CNN preds
max_features_re = max_features.copy().reshape(len(max_features), 11, 1)

#Predictions with CNN1
cnn1_pred = cnn1.predict(max_features_re)
cnn1_pred = np.array([0 if i[0] < 0.5 else 1 for i in cnn1_pred])
#accuracy of CNN1
print(f"Accuracy of CNN1: {accuracy_score(max_labels, cnn1_pred)}%")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, cnn1_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#Predictions with CNN2
cnn2_pred = cnn2.predict(max_features_re)
cnn2_pred = np.array([0 if i[0] < 0.5 else 1 for i in cnn2_pred])
#accuracy of CNN2
print(f"Accuracy of CNN2: {accuracy_score(max_labels, cnn2_pred)}%")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, cnn2_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#Predictions with CNN3
cnn3_pred = cnn3.predict(max_features_re)
cnn3_pred = np.array([0 if i[0] < 0.5 else 1 for i in cnn3_pred])
#accuracy of CNN3
print(f"Accuracy of CNN3: {accuracy_score(max_labels, cnn3_pred)}%")
#Confusion Matrix
tn, fp, fn, tp = confusion_matrix(max_labels, cnn3_pred).ravel()
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")